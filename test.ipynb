{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dst\n",
    "\n",
    "from utils import AverageMeter, accuracy, transform_time\n",
    "from utils import load_pretrained_model, save_checkpoint\n",
    "from utils import create_exp_dir, count_parameters_in_MB\n",
    "from network import define_tsnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"test r20 net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--img_root'], dest='img_root', nargs=None, const=None, default='./datasets', type=<class 'str'>, choices=None, required=False, help='path name of image dataset', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# various path\n",
    "parser.add_argument(\n",
    "    \"--save_root\", type=str, default=\"./results\", help=\"models and logs are saved here\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--img_root\", type=str, default=\"./datasets\", help=\"path name of image dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--cuda'], dest='cuda', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training hyper parameters\n",
    "parser.add_argument(\n",
    "    \"--print_freq\",\n",
    "    type=int,\n",
    "    default=50,\n",
    "    help=\"frequency of showing training results on console\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--epochs\", type=int, default=200, help=\"number of total epochs to run\"\n",
    ")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=128, help=\"The size of batch\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.1, help=\"initial learning rate\")\n",
    "parser.add_argument(\"--momentum\", type=float, default=0.9, help=\"momentum\")\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=1e-4, help=\"weight decay\")\n",
    "parser.add_argument(\"--num_class\", type=int, default=100, help=\"number of classes\")\n",
    "parser.add_argument(\"--cuda\", type=int, default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--note'], dest='note', nargs=None, const=None, default='test-c100-r20', type=<class 'str'>, choices=None, required=False, help='note for this run', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# others\n",
    "parser.add_argument(\"--seed\", type=int, default=2, help=\"random seed\")\n",
    "parser.add_argument(\"--note\", type=str, default=\"test-c100-r20\", help=\"note for this run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--net_name'], dest='net_name', nargs=None, const=None, default='resnet20', type=<class 'str'>, choices=None, required=True, help='name of basenet', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net and dataset choosen\n",
    "parser.add_argument(\n",
    "    \"--data_name\", type=str, default=\"cifar100\", required=True, help=\"name of dataset\"\n",
    ")  # cifar10/cifar100\n",
    "parser.add_argument(\n",
    "    \"--net_name\", type=str, default=\"resnet20\",required=True, help=\"name of basenet\"\n",
    ")  # resnet20/resnet110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--save_root SAVE_ROOT]\n",
      "                             [--img_root IMG_ROOT] [--print_freq PRINT_FREQ]\n",
      "                             [--epochs EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                             [--lr LR] [--momentum MOMENTUM]\n",
      "                             [--weight_decay WEIGHT_DECAY]\n",
      "                             [--num_class NUM_CLASS] [--cuda CUDA]\n",
      "                             [--seed SEED] [--note NOTE] --data_name DATA_NAME\n",
      "                             --net_name NET_NAME\n",
      "ipykernel_launcher.py: error: the following arguments are required: --data_name, --net_name\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corner/.conda/envs/KD/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "args, unparsed = parser.parse_known_args()\n",
    "\n",
    "args.save_root = os.path.join(args.save_root, args.note)\n",
    "create_exp_dir(args.save_root)\n",
    "\n",
    "log_format = \"%(message)s\"\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=log_format)\n",
    "fh = logging.FileHandler(os.path.join(args.save_root, \"log.txt\"))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, net, criterion):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    for i, (img, target) in enumerate(test_loader, start=1):\n",
    "        if args.cuda:\n",
    "            img = img.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, _, _, _, _, out = net(img)\n",
    "            loss = criterion(out, target)\n",
    "\n",
    "        prec1, prec5 = accuracy(out, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), img.size(0))\n",
    "        top1.update(prec1.item(), img.size(0))\n",
    "        top5.update(prec5.item(), img.size(0))\n",
    "\n",
    "    f_l = [losses.avg, top1.avg, top5.avg]\n",
    "    logging.info(\"Loss: {:.4f}, Prec@1: {:.2f}, Prec@5: {:.2f}\".format(*f_l))\n",
    "\n",
    "    return top1.avg, top5.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        cudnn.enabled = True\n",
    "        cudnn.benchmark = True\n",
    "    logging.info(\"args = %s\", args)\n",
    "    logging.info(\"unparsed_args = %s\", unparsed)\n",
    "\n",
    "    logging.info(\"----------- Network Initialization --------------\")\n",
    "\n",
    "    # 加载模型\n",
    "    net = define_tsnet(name=args.net_name, num_class=args.num_class, cuda=args.cuda)\n",
    "    checkpoint = torch.load(\"/home/corner/Knowledge-Distillation-Zoo/results/base/test-c100-r20/initial_r20.pth.tar\")\n",
    "    net.load_state_dict(checkpoint[\"net\"])\n",
    "    logging.info(\"%s\", net)\n",
    "    logging.info(\"param size = %fMB\", count_parameters_in_MB(net))\n",
    "    logging.info(\"-----------------------------------------------\")\n",
    "\n",
    "    # save initial parameters\n",
    "    logging.info(\"Saving initial parameters......\")\n",
    "    save_path = os.path.join(\n",
    "        args.save_root, \"initial_r{}.pth.tar\".format(args.net_name[6:])\n",
    "    )\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": 0,\n",
    "            \"net\": net.state_dict(),\n",
    "            \"prec@1\": 0.0,\n",
    "            \"prec@5\": 0.0,\n",
    "        },\n",
    "        save_path,\n",
    "    )\n",
    "\n",
    "    # define loss functions\n",
    "    if args.cuda:\n",
    "        criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "    else:\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # define transforms\n",
    "    if args.data_name == \"cifar100\":\n",
    "        dataset = dst.CIFAR100\n",
    "        mean = (0.5071, 0.4865, 0.4409)\n",
    "        std = (0.2673, 0.2564, 0.2762)\n",
    "    else:\n",
    "        raise Exception(\"Invalid dataset name...\")\n",
    "\n",
    "    train_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Pad(4, padding_mode=\"reflect\"),\n",
    "            transforms.RandomCrop(32),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "        ]\n",
    "    )\n",
    "    test_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # define data loader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset(\n",
    "            root=args.img_root, transform=train_transform, train=True, download=True\n",
    "        ),\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset(\n",
    "            root=args.img_root, transform=test_transform, train=False, download=True\n",
    "        ),\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        # evaluate on testing set\n",
    "        logging.info(\"Testing the models......\")\n",
    "        test_top1, test_top5 = test(test_loader, net, criterion)\n",
    "\n",
    "        # save model\n",
    "        logging.info(f\"Saving models for epoch{epoch}......\")\n",
    "        save_path = os.path.join(\n",
    "            args.save_root, \"epoch_{}.pth.tar\".format(epoch)\n",
    "        )\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"net\": net.state_dict(),\n",
    "            \"prec@1\": test_top1,\n",
    "            \"prec@5\": test_top5,\n",
    "        }, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
